{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashant-gulati/colab/blob/main/Deep_Learning_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vtoIQjcvai1"
      },
      "outputs": [],
      "source": [
        "#https://www.youtube.com/watch?v=SY9o3jvuVbg\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate a 2D binary classification dataset\n",
        "X, y = make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0,\n",
        "                           n_clusters_per_class=1, random_state=42)\n",
        "\n",
        "# 2. Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 3. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FJhLgRycvqc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define a simple neural network model in Keras\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(2,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the model and capture training history\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.2)"
      ],
      "metadata": {
        "id": "sG5BV4yvwOgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Plot the dataset\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap='bwr', edgecolors='k', alpha=0.7)\n",
        "plt.title(\"2D Binary Classification Dataset\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.grid(True)\n",
        "\n",
        "# 8. Plot accuracy over epochs\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy vs Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3wVke2NQxMao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "dlh22ld00QZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=2, n_redundant=0,\n",
        "                           n_informative=2, n_clusters_per_class=1, random_state=42)\n",
        "\n",
        "# 2. Scale and split (train and test)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "1s7FROEz0SD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Visualize dataset\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap='bwr', edgecolors='k')\n",
        "plt.title(\"2D Binary Classification Dataset\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VwaO5yer0VCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Define the model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 10)\n",
        "        self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "cUqX5k9W0xC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN(input_dim=2)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "A5ufDzjn1RQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train the model\n",
        "num_epochs = 30\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Training accuracy\n",
        "        train_preds = (outputs >= 0.5).float()\n",
        "        train_acc = accuracy_score(y_train_tensor.numpy(), train_preds.numpy())\n",
        "\n",
        "        # Test accuracy\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_preds = (test_outputs >= 0.5).float()\n",
        "        test_acc = accuracy_score(y_test_tensor.numpy(), test_preds.numpy())\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_accuracies.append(test_acc)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "GYoxcmV81Z8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Plot loss and combined accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses, label=\"Loss\", color='red')\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Combined Accuracy Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label=\"Train Accuracy\", color='green')\n",
        "plt.plot(test_accuracies, label=\"Test Accuracy\", color='orange')\n",
        "plt.title(\"Train vs Test Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vQBu7U_D1--v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}